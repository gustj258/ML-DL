{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다운로드 완료\n"
     ]
    }
   ],
   "source": [
    "baseUrl = 'https://chilgok.fowi.or.kr/facility/lodge.do'\n",
    "url = baseUrl\n",
    "\n",
    "html = urlopen(url).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "img = soup.find_all(class_='_img')\n",
    "\n",
    "n = 1\n",
    "for i in img:\n",
    "    imgUrl = i['썸네일']\n",
    "    with urlopen(imgUrl) as f:\n",
    "        with open('./img/' + str(n) + '.jpg', 'wb') as h:\n",
    "            img = f.read()\n",
    "            h.write(img)\n",
    "    n += 1\n",
    "    print(imgUrl)\n",
    "\n",
    "print('다운로드 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# builtin module\n",
    "from datetime import datetime\n",
    "\n",
    "# pip install module\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# user defined module\n",
    "from util.myRedis import SimpleRedis\n",
    "from util.redis_insert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_TPL = \"http://comic.naver.com/webtoon/list.nhn?titleId=20853&weekday=tue&page={}\"\n",
    "\n",
    "def get_html(url):\n",
    "\t_html = \"\"\n",
    "\tresp = requests.get(url)\n",
    "\tif resp.status_code == 200:\n",
    "\t\t_html = resp.text\n",
    "\treturn _html\n",
    "\n",
    "\n",
    "def parse_html(html):\n",
    "\t\"\"\"\n",
    "\t입력받은 마음의 소리 웹툰 페이지 html에서 마음의소리의 회차, 제목 url을 추출하여\n",
    "\ttuple로 만들고, 리스트에 갯수대로 저장하여 반환한다\n",
    "\t:param html: string\n",
    "\t:return: 마음의 소리 정보가 담긴 리스트\n",
    "\t\"\"\"\n",
    "\twebtoon_list = list()\n",
    "\tsoup = BeautifulSoup(html, 'html.parser')\n",
    "\twebtoon_area = soup.find(\"table\",\n",
    "\t\t\t{\"class\": \"viewList\"}\n",
    "\t        ).find_all(\"td\", {\"class\":\"title\"})\n",
    "\tfor webtoon_index in webtoon_area:\n",
    "\t\tinfo_soup = webtoon_index.find(\"a\")\n",
    "\t\t_url = info_soup[\"href\"]\n",
    "\t\t_text = info_soup.text.split(\".\")\n",
    "\t\t_title  = \"\"\n",
    "\t\t_num = _text[0]\n",
    "\t\tif len(_text) > 1:\n",
    "\t\t\t_title = _text[1]\n",
    "\t\t\t\n",
    "\t\twebtoon_list.append((_num, _title, _url, ))\n",
    "\treturn webtoon_list\n",
    "\n",
    "def collect_one_page(page_index):\n",
    "\turl = URL_TPL.format(page_index)\n",
    "\t\n",
    "\tres_html = get_html(url)\n",
    "\tres_parse = parse_html(res_html)\n",
    "\treturn res_parse\n",
    "\t\n",
    "def get_pageindex_from_redis(simple_redis):\n",
    "\ttotal = 0\n",
    "\twhile True:\n",
    "\t\tindexes = simple_redis.redisQ_pop(\"page\")\n",
    "\t\tif indexes is None:\n",
    "\t\t\tbreak\n",
    "\t\tfor index in indexes:\n",
    "\t\t\tinfos = collect_one_page(index)\n",
    "\t\t\tinsert_webtoon_info(simple_redis, infos)\n",
    "\t\t\ttotal += 1\n",
    "\t\n",
    "\tprint(\"{} 저장되었습니다\".format(total))\n",
    "\t\t\n",
    "def insert_webtoon_info(simple_redis, infos):\n",
    "\tfor info in infos:\n",
    "\t\tres = simple_redis.redis_hash_set(\"maso\", info[0], info)\n",
    "\t\t\t\n",
    "\n",
    "def do_main():\n",
    "\tsr = SimpleRedis()\n",
    "\tget_pageindex_from_redis(sr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tdo_insert()\n",
    "\tsts = datetime.now()\n",
    "\tdo_main()\n",
    "\tets = datetime.now()\n",
    "\t\n",
    "\tprint(\"elapse : {}\".format(ets-sts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://apis.data.go.kr/1360000/TyphoonInfoService/getTyphoonInfo'\n",
    "queryParams = '?' + urlencode({ quote_plus('ServiceKey') : '3w68NZC3y7WLN4yWYQe%2F0%2FaQFOD1gwWOn6hJqe30ILw6GDoFiF0%2FzjloMWbUTtU0zGbZnvL5ob2ZakxK4IiPmg%3D%3D', quote_plus('ServiceKey') : '-', quote_plus('pageNo') : '1', quote_plus('numOfRows') : '10', quote_plus('dataType') : 'XML', quote_plus('fromTmFc') : '20120928', quote_plus('toTmFc') : '20120928' })\n",
    "\n",
    "request = Request(url + queryParams)\n",
    "request.get_method = lambda: 'GET'\n",
    "response_body = urlopen(request).read()\n",
    "print response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
